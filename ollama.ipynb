{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-AkKMcj4D9R",
        "outputId": "cf264d02-dbbc-490b-88fa-436a48685fd1"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DIhR97g4awD"
      },
      "source": [
        "## Install Ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1tDsDud4kM7",
        "outputId": "aacb1a54-694b-4e0f-dccc-ba6c84fbc608"
      },
      "outputs": [],
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RxgR3qSh41QC"
      },
      "outputs": [],
      "source": [
        "!pip install -qq pyngrok ollama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHUjxXK1FpS2"
      },
      "source": [
        "## Install Ollama Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACz3MyjDFyfW",
        "outputId": "a0110669-56b6-4715-ac4c-3858a697a176"
      },
      "outputs": [],
      "source": [
        "!ollama pull nomic-embed-text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hwqeLTfGB6d",
        "outputId": "f4254321-5d9e-4c62-f490-fa3afce20647"
      },
      "outputs": [],
      "source": [
        "!ollama pull phi3:3.8b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHK6yZFl5Kdn"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lBta5qZ55OXh"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "import subprocess\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "from typing import Any, Dict, List, Optional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAGMVUUv5nTJ"
      },
      "source": [
        "## Auxiliary Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GZvjAUAG5snQ"
      },
      "outputs": [],
      "source": [
        "def start_ollama_server() -> None:\n",
        "  \"\"\"Starts the Ollama server.\"\"\"\n",
        "  subprocess.Popen(['ollama', 'serve'])\n",
        "  print(\"Ollama server started.\")\n",
        "\n",
        "def check_ollama_port(port: str) -> None:\n",
        "  \"\"\"Check if Ollama server is running at the specified port.\"\"\"\n",
        "  try:\n",
        "      subprocess.run(['sudo', 'lsof', '-i', '-P', '-n'], check=True, capture_output=True, text=True)\n",
        "      if any(f\":{port} (LISTEN)\" in line for line in subprocess.run(['sudo', 'lsof', '-i', '-P', '-n'], capture_output=True, text=True).stdout.splitlines()):\n",
        "        print(f\"Ollama is listening on port {port}\")\n",
        "      else:\n",
        "        print(f\"Ollama does not appear to be listening on port {port}.\")\n",
        "  except subprocess.CalledProcessError as e:\n",
        "      print(f\"Error checking Ollama port: {e}\")\n",
        "\n",
        "def setup_ngrox_tunnel(port: str) -> ngrok.NgrokTunnel:\n",
        "  \"\"\"Sets up an ngrok tunnel.\n",
        "\n",
        "  Args:\n",
        "    port: Th port to tunnel.\n",
        "\n",
        "  Returns:\n",
        "    The ngrok tunnel object.\n",
        "\n",
        "  Raises:\n",
        "    RuntimeError: If the ngrok authentoken is not set.\n",
        "  \"\"\"\n",
        "  ngrok_auth_token = userdata.get('NGROK_AUTHTOKEN')\n",
        "  if not ngrok_auth_token:\n",
        "      raise RuntimeError(\"NGROK_AUTHTOKEN is not set.\")\n",
        "\n",
        "  ngrok.set_auth_token(ngrok_auth_token)\n",
        "  tunnel = ngrok.connect(port, host_header=f'localhost:{port}')\n",
        "  print(f\"ngrok tunnel created: {tunnel.public_url}\")\n",
        "  return tunnel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYS6YKSl8b1h"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fDxyoH5A8fkj"
      },
      "outputs": [],
      "source": [
        "NGROK_PORT = '11434'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6Ef1aKF87eu"
      },
      "source": [
        "# Start the `Ollama` server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9_QtZ0Q8_v6",
        "outputId": "a309edbb-d3bf-41d4-c3d4-a76849e3fd1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ollama server started.\n",
            "Ollama is listening on port 11434\n"
          ]
        }
      ],
      "source": [
        "start_ollama_server()\n",
        "\n",
        "check_ollama_port(NGROK_PORT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjgJdEnK9I7-"
      },
      "source": [
        "## Setup ngrok `ngrok` tunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmZJlkm19Q1P",
        "outputId": "c857ec64-9387-489a-fd64-1c2a4cfdb297"
      },
      "outputs": [],
      "source": [
        "ngrok_tunnel = setup_ngrox_tunnel(NGROK_PORT)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
